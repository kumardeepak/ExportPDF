{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reportlab.platypus import Paragraph, SimpleDocTemplate, Spacer  \n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle   \n",
    "from reportlab.lib.enums import TA_CENTER,TA_JUSTIFY       \n",
    "from reportlab.pdfbase import pdfmetrics      \n",
    "from reportlab.pdfbase.ttfonts import TTFont   \n",
    "from reportlab.lib.fonts import addMapping\n",
    "from reportlab.lib.pagesizes import letter, A4\n",
    "from reportlab.pdfgen import canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_pages(filename, encoding='utf-8'):\n",
    "    with open(filename, 'r', encoding=encoding) as f:\n",
    "        data = json.load(f)\n",
    "    return data['inputs'][0]['pages']\n",
    "\n",
    "def vertices_to_boundingbox(vertices):\n",
    "    c1, c2, c3, c4  = vertices[0], vertices[1], vertices[2], vertices[3]\n",
    "    left, top       = c1['x'], c1['y']\n",
    "    width, height   = (c3['x'] - c1['x']), (c3['y'] - c1['y'])\n",
    "    return (left, top, width, height)\n",
    "\n",
    "def get_page_words(page):\n",
    "    if 'regions' not in page.keys():\n",
    "        return []\n",
    "    words = []\n",
    "    for region in page['regions']:\n",
    "        if 'class' in region.keys() and 'regions' in region.keys():\n",
    "            if region['class'] == 'PARA':\n",
    "                lines = region['regions']\n",
    "                for line in lines:\n",
    "                    if 'regions' in line.keys():\n",
    "                        for word in line['regions']:\n",
    "                            words.append(word)\n",
    "    return words\n",
    "\n",
    "def words_to_dataframe(words):\n",
    "    texts      = []\n",
    "    tops       = []\n",
    "    lefts      = []\n",
    "    widths     = []\n",
    "    heights    = []\n",
    "    font_sizes = []\n",
    "\n",
    "    for word in words:\n",
    "        if 'text' in word.keys() and len(word['text']) != 0:\n",
    "            texts.append(word['text'])\n",
    "            left, top, width, height = vertices_to_boundingbox(word['boundingBox']['vertices'])\n",
    "            tops.append(top)\n",
    "            lefts.append(left)\n",
    "            widths.append(width)\n",
    "            heights.append(height)\n",
    "            font_sizes.append(word['font']['size'])\n",
    "\n",
    "    df = pd.DataFrame(list(zip(texts, tops, lefts, widths, heights,font_sizes)), \n",
    "                          columns =['text', 'top', 'left', 'width', 'height', 'font_size'])\n",
    "    \n",
    "    df1 = df.sort_values(['top', 'left'], ascending=[True, True])\n",
    "    df1.reset_index(inplace=True)\n",
    "\n",
    "    return df1\n",
    "\n",
    "def show_df(df):\n",
    "    return df.head(df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# directory setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR      = os.path.dirname(os.getcwd())\n",
    "FONT_DIR         = os.path.join(WORKING_DIR, 'font')\n",
    "\n",
    "DATA_DIR         = os.path.join(WORKING_DIR, 'data')\n",
    "DATA_INPUT_DIR   = os.path.join(DATA_DIR, 'input')\n",
    "DATA_OUTPUT_DIR  = os.path.join(DATA_DIR, 'output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading vernacular kannada font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "FONT_NAME        = 'lohit_ta'\n",
    "FONT_FILENAME    = os.path.join(FONT_DIR, FONT_NAME + '.ttf')\n",
    "pdfmetrics.registerFont(TTFont(FONT_NAME, FONT_FILENAME)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename         = '6.tamil.json'\n",
    "input_filepath   = os.path.join(DATA_INPUT_DIR, filename)\n",
    "output_filepath  = os.path.join(DATA_OUTPUT_DIR, filename + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of pages in document 3\n"
     ]
    }
   ],
   "source": [
    "pages  = get_document_pages(input_filepath)\n",
    "print('total number of pages in document %d' % (len(pages)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'vertices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a62d3781ae09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpage\u001b[0m                          \u001b[0;34m=\u001b[0m \u001b[0mpages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_height\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvertices_to_boundingbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vertices'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mwords\u001b[0m                         \u001b[0;34m=\u001b[0m \u001b[0mget_page_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m                            \u001b[0;34m=\u001b[0m \u001b[0mwords_to_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'total number of words %d, page_width %d, page_height %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'vertices'"
     ]
    }
   ],
   "source": [
    "page                          = pages[0]\n",
    "_, _, page_width, page_height = vertices_to_boundingbox(page['vertices'])\n",
    "words                         = get_page_words(page)\n",
    "df                            = words_to_dataframe(words)\n",
    "print('total number of words %d, page_width %d, page_height %d' % (len(words), page_width, page_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE_FACTOR_A4_72DPI = 4\n",
    "\n",
    "c = canvas.Canvas(output_filepath, pagesize=(page_width/SCALE_FACTOR_A4_72DPI, page_height/SCALE_FACTOR_A4_72DPI))\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    text, left, top, font_size = row['text'], row['left'], page_height - row['top'], row['font_size']\n",
    "    c.setLineWidth(0.5)\n",
    "    c.setFont(FONT_NAME, 30/SCALE_FACTOR_A4_72DPI)\n",
    "    c.drawString(left/SCALE_FACTOR_A4_72DPI, top/SCALE_FACTOR_A4_72DPI, text)\n",
    "\n",
    "c.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pdf_file(pages, pdf_filepath):\n",
    "    SCALE_FACTOR_A4_72DPI = 4\n",
    "#     page_size             = (page_width/SCALE_FACTOR_A4_72DPI, page_height/SCALE_FACTOR_A4_72DPI))\n",
    "    c                     = canvas.Canvas(pdf_filepath, pagesize=A4)\n",
    "\n",
    "    for page in pages:\n",
    "        _, _, page_width, page_height = vertices_to_boundingbox(page['vertices'])\n",
    "        words                         = get_page_words(page)\n",
    "        df                            = words_to_dataframe(words)\n",
    "        print('total number of words %d, page_width %d, page_height %d' % (len(words), page_width, page_height))\n",
    "        \n",
    "        for index, row in df.iterrows():\n",
    "            text, left, top, font_size = row['text'], row['left'], page_height - row['top'], row['font_size']\n",
    "            c.setLineWidth(0.5)\n",
    "            c.setFont(FONT_NAME, 30/SCALE_FACTOR_A4_72DPI)\n",
    "            c.drawString(left/SCALE_FACTOR_A4_72DPI, top/SCALE_FACTOR_A4_72DPI, text)\n",
    "        \n",
    "        c.showPage()\n",
    "\n",
    "    c.save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pdf]",
   "language": "python",
   "name": "conda-env-pdf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
